{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import os\n",
    "from imutils.video import FPS\n",
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing video...\n",
      "hello\n",
      "0.00019979476928710938\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/mtcnn.py:187: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/mtcnn.py:193: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/network.py:43: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/layer_factory.py:88: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/layer_factory.py:79: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/layer_factory.py:171: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/user/anaconda3/lib/python3.7/site-packages/mtcnn/layer_factory.py:196: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "[INFO] Total elasped time of video: 124.93 seconds\n",
      "[INFO] approx. FPS: 0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] processing video...\")\n",
    "stream = cv2.VideoCapture(\"cam2.mp4\")\n",
    "fps = FPS().start()\n",
    "writer = None\n",
    "display=1\n",
    "count=0\n",
    "\n",
    "start = time.time()\n",
    "print(\"hello\")\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "framecount=0\n",
    "filename=\"./groupphoto/videooutput/\"\n",
    "# loop over frames from the video file stream\n",
    "detector = MTCNN()\n",
    "while True:\n",
    "\t# grab the next frame\n",
    "\tstart = time.time()\n",
    "\t(grabbed, frame) = stream.read()\n",
    "\tcount = 0\n",
    "\t# if the frame was not grabbed, then we have reached the\n",
    "\t# end of the stream\n",
    "\tif not grabbed:\n",
    "\t\tbreak \n",
    "\t#(h1,w1) = frame.shape[:2]\n",
    "\t#print(\"frame height\" +str(h1) + \" width \" + str(w1))\n",
    "\t#image = imutils.resize(frame, height=800 , width=800)\n",
    "\timage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\t(h, w) = image.shape[:2]\n",
    "\tresult=detector.detect_faces(image)\n",
    "        #Iterate over all of the faces detected and extract their start and end points\n",
    "        \n",
    "\tfor i in result:\n",
    "\t\tbounding_box = i['box']\n",
    "#             boxes = boxes * numpy.array([w, h, w, h])\n",
    "#             (startX, startY, endX, endY) = boxes.astype(\"int\")\n",
    "\t\tconfidence1 =i['confidence']\n",
    "            #if the algorithm is more than 16.5% confident that the      detection is a face, show a rectangle around it\n",
    "\t\tif (confidence1 > 0.165):\n",
    "\t\t\tcv2.rectangle(image, (bounding_box[0], bounding_box[1]),\n",
    "\t\t\t\t(bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]), (random.randint(0,255),random.randint(0,255)  , random.randint(0,255)) , 2)\n",
    "\t\t\tend = time.time()\n",
    "\t\t\ttext=str(format( (end-start), '0.3f'))+' sec.'\n",
    "\t\t\tcv2.putText(image, text, (10, 10),\n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 2)\n",
    "\t\t\tcount = count + 1    #save the modified image to the Output folder\n",
    "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\t\t#cv2.imwrite(filename + str(framecount)+'.jpg', image)\n",
    "\t\tframecount+=1\n",
    "        \n",
    "# \tif writer is not None:\n",
    "# \t\twriter.write(image)\n",
    "\n",
    "\tif display > 0:\n",
    "\t\tcv2.imshow(\"Frame\", image)\n",
    "\t\tfps.update()\n",
    "\t\tkey = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "\t\t# if the `q` key was pressed, break from the loop\n",
    "\t\tif key == ord(\"q\"):\n",
    "\t\t\tbreak\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "fps.stop()\n",
    "print(\"[INFO] Total elasped time of video: {:.2f} seconds\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    " \n",
    "# do a bit of cleanup\n",
    "stream.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# check to see if the video writer point needs to be released\n",
    "if writer is not None:\n",
    "\twriter.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection complete for image 32405483698_b67eafbca8_b.jpg (83) faces found!\n",
      "Face detection complete for image migrants.jpg (4) faces found!\n",
      "Face detection complete for image FC1.jpg (41) faces found!\n",
      "Face detection complete for image r0_272_5568_3415_w1200_h678_fmax.jpg (55) faces found!\n",
      "Face detection complete for image kashmir_1479570524.jpeg (2) faces found!\n",
      "Face detection complete for image merlin_155970570_d787c29e-a416-46fb-afa5-567dd1cd90b9-jumbo.jpg (16) faces found!\n",
      "Face detection complete for image alex-prager-faces-in-the-crowd-12.jpg (30) faces found!\n",
      "Face detection complete for image 8280754-3x2-700x467.jpg (86) faces found!\n",
      "Face detection complete for image 180726-grand-central-crowd-mn-1540_a7dd9985d249b6b08a6ebd51c28887c4.fit-760w.jpg (32) faces found!\n",
      "Face detection complete for image robin-flckr-traffic-india.jpg (0) faces found!\n",
      "Face detection complete for image mc-central-at-whitehall-faces-in-the-crowd-20140905.jpg (21) faces found!\n",
      "Face detection complete for image Exhibitions-watch-this-2017-face-in-the-crowd.jpg (11) faces found!\n",
      "Face detection complete for image large-crowd-of-faces-celebrates-at-chester-city-football-club-deva-AWR46D.jpg (20) faces found!\n",
      "Face detection complete for image PAFF_022619_facescrowd-609x419.jpg (66) faces found!\n",
      "Face detection complete for image mc-pictures-faces-easton-emmaus-football-20180921.jpg (28) faces found!\n",
      "Face detection complete for image IMG_0009-1080x675.jpg (8) faces found!\n",
      "Face detection complete for image WireAP_7d447101a3ef48f1bbdb649c67f28696_12x5_992.jpg (22) faces found!\n",
      "Face detection complete for image c1b89de6-30d2-11e8-9019-a420e6317de0_1280x720_175232.jpg (0) faces found!\n",
      "Face detection complete for image 2013_ap_crowd_4_new_haven_press_cut.jpg (17) faces found!\n",
      "Total time taken for all files 72.22476363182068 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "# protoPath =  \"./face_detection_model/deploy.prototxt\"\n",
    "# modelPath = \"./face_detection_model/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "# #import libraries\n",
    "# import os   \n",
    "# import cv2\n",
    "# import numpy#get the absolute path of the working directory\n",
    "dir_path = \"/home/user/groupphoto/faces_tough\"\n",
    "# dir_path1= \"./groupphoto/group1Output\"\n",
    "#create the Output folder if it doesn't already exist\n",
    "\n",
    "# model = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "\n",
    "#img = cv2.cvtColor(cv2.imread(\"ivan.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "# detector = MTCNN()\n",
    "# print(detector.detect_faces(img))\n",
    "startfolder=time.time()\n",
    "for file in os.listdir(dir_path):\n",
    "      #split the file name and the extension into two variales\n",
    "    filename, file_extension = os.path.splitext(file)#check if the file extension is .png,.jpeg or .jpg \n",
    "    if (file_extension in ['.png','.jpg','.jpeg']):\n",
    "        #read the image using cv2\n",
    "        count = 0\n",
    "         # etc ...\n",
    "#         red1 = 100; white1 = 100 ; blue1 = 50\n",
    "        start = time.time()\n",
    "        #image = cv2.imread(dir_path+\"/\"+file)\n",
    "        image = cv2.cvtColor(cv2.imread(dir_path+\"/\"+file), cv2.COLOR_BGR2RGB)\n",
    "#         image = cv2.imread(dir_path+\"/\"+file)#accessing the image.shape tuple and taking the elements\n",
    "        (h, w) = image.shape[:2]#get our blob which is our input image \n",
    "#         blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "#         #input the blob into the model and get back the detections \n",
    "#         model.setInput(blob)\n",
    "#         detections = model.forward()\n",
    "        #fontScale = (w * h) / (1000 * 1000)\n",
    "        detector = MTCNN()\n",
    "        result=detector.detect_faces(image)\n",
    "        #Iterate over all of the faces detected and extract their start and end points\n",
    "      \n",
    "        for i in result:\n",
    "            bounding_box = i['box']\n",
    "\n",
    "            \n",
    "#             boxes = boxes * numpy.array([w, h, w, h])\n",
    "#             (startX, startY, endX, endY) = boxes.astype(\"int\")\n",
    "            confidence1 =i['confidence']\n",
    "            #if the algorithm is more than 16.5% confident that the      detection is a face, show a rectangle around it\n",
    "            if (confidence1 > 0.165):\n",
    "                cv2.rectangle(image, (bounding_box[0], bounding_box[1]),\n",
    "                    (bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]), (random.randint(0,255),random.randint(0,255)  , random.randint(0,255)) , 2)\n",
    "#                 red1=red1+10 ; blue1= blue1+10 ; white1= white1+10\n",
    "                \n",
    "                end = time.time()\n",
    "                text=str(format( (end-start), '0.3f'))+' sec.' + ' faces: ' +str(count) \n",
    "                cv2.putText(image, text, (1, 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.50 , (255, 255, 255), 2)\n",
    "                count = count + 1    #save the modified image to the Output folder\n",
    "         \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        cv2.imwrite('/home/user/groupphoto/face_tough_output2/' + file, image)    #print out a success message\n",
    "    print(\"Face detection complete for image \"+ file + \" (\"+ str(count) +\") faces found!\")\n",
    "endfolder=time.time()\n",
    "print(\"Total time taken for all files \" +str(endfolder-startfolder)+' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
